import os
import json
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import numpy as np
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm
import argparse
from pathlib import Path
import logging
from datetime import datetime
from torchvision.transforms.functional import pad

from src.pipeline import FluxPipeline
from src.transformer_flux import FluxTransformer2DModel
from src.lora_helper import set_single_lora

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LAIONFaceDataset(Dataset):
    """
    LAIONFaceæ•°æ®é›†åŠ è½½å™¨
    æ•°æ®ç»“æ„å‡è®¾ï¼š
    data_root/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ 000000.jpg
    â”‚   â”œâ”€â”€ 000001.jpg
    â”‚   â””â”€â”€ ...
    â””â”€â”€ metadata.json  # åŒ…å«å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    """
    def __init__(self, data_root: str, subset_size: Optional[int] = None):
        self.data_root = Path(data_root)
        self.images_dir = self.data_root
        
        # å¦‚æœæœ‰metadataæ–‡ä»¶å°±è¯»å–ï¼Œå¦åˆ™æ‰«æimagesç›®å½•
        metadata_path = self.data_root / "metadata.json"
        if metadata_path.exists():
            with open(metadata_path, 'r') as f:
                self.image_paths = json.load(f)
        else:
            # æ‰«æimagesç›®å½•ï¼Œæ”¯æŒå¸¸è§å›¾ç‰‡æ ¼å¼
            extensions = ['.jpg', '.jpeg', '.png', '.bmp']
            self.image_paths = []
            for ext in extensions:
                self.image_paths.extend(list(self.images_dir.glob(f"*{ext}")))
                self.image_paths.extend(list(self.images_dir.glob(f"*{ext.upper()}")))
            self.image_paths = [str(p) for p in self.image_paths]
        
        # å¦‚æœæŒ‡å®šäº†å­é›†å¤§å°ï¼Œå°±éšæœºé‡‡æ ·
        if subset_size and subset_size < len(self.image_paths):
            np.random.seed(42)  # å›ºå®šç§å­ç¡®ä¿å¯å¤ç°
            indices = np.random.choice(len(self.image_paths), subset_size, replace=False)
            self.image_paths = [self.image_paths[i] for i in indices]
        
        logger.info(f"Loaded {len(self.image_paths)} images from {data_root}")
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        
        # å¦‚æœè·¯å¾„æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°±åŠ ä¸Šdata_root
        if not os.path.isabs(image_path):
            image_path = self.images_dir / image_path
        
        try:
            image = Image.open(image_path).convert("RGB")
            return {
                'image': image,
                'image_path': str(image_path),
                'index': idx
            }
        except Exception as e:
            logger.warning(f"Failed to load image {image_path}: {e}")
            # è¿”å›ä¸€ä¸ªç©ºç™½å›¾ç‰‡ä½œä¸ºfallback
            dummy_image = Image.new('RGB', (512, 512), color='white')
            return {
                'image': dummy_image,
                'image_path': str(image_path),
                'index': idx
            }

class OptimizedAdversarialGenerator:
    def __init__(self, 
                 base_path: str = "/openbayes/input/input0",
                 subject_lora_path: str = "/openbayes/input/input0/subject.safetensors",
                 device: str = "cuda",
                 output_dir: str = "./adversarial_results"):
        """
        ä¼˜åŒ–ç‰ˆå¤§è§„æ¨¡å¯¹æŠ—æ ·æœ¬ç”Ÿæˆå™¨
        
        Args:
            base_path: FLUXåŸºç¡€æ¨¡å‹è·¯å¾„
            subject_lora_path: subject control LoRAæ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
            output_dir: è¾“å‡ºç›®å½•
        """
        self.device = device
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.clean_dir = self.output_dir / "clean_images"
        self.adversarial_dir = self.output_dir / "adversarial_images"
        self.logs_dir = self.output_dir / "logs"
        
        for dir_path in [self.clean_dir, self.adversarial_dir, self.logs_dir]:
            dir_path.mkdir(exist_ok=True)
        
        logger.info("Initializing EasyControl pipeline...")
        self._init_pipeline(base_path, subject_lora_path)
        
        # ä½¿ç”¨å•ä¸ªæ”»å‡»prompt
        self.attack_prompt = "A SKS on the beach"
        
        logger.info(f"Using attack prompt: '{self.attack_prompt}'")
    def investigate_pipeline_processor(self):
        """
        è°ƒæŸ¥ä½ çš„pipeline image processoråˆ°åº•åšäº†ä»€ä¹ˆ
        """
        print("=" * 60)
        print("INVESTIGATING PIPELINE IMAGE PROCESSOR")
        print("=" * 60)

        # æ£€æŸ¥processorç±»å‹å’Œå±æ€§
        processor = self.pipe.image_processor
        print(f"Processor type: {type(processor)}")
        print(f"Processor dir: {[attr for attr in dir(processor) if not attr.startswith('_')]}")

        # æ£€æŸ¥æ˜¯å¦æœ‰normalizeå‚æ•°
        if hasattr(processor, 'do_normalize'):
            print(f"do_normalize: {processor.do_normalize}")
        if hasattr(processor, 'image_mean'):
            print(f"image_mean: {processor.image_mean}")
        if hasattr(processor, 'image_std'):
            print(f"image_std: {processor.image_std}")
        if hasattr(processor, 'config'):
            print(f"config: {processor.config}")

        # æµ‹è¯•ä¸€ä¸ªç®€å•çš„çº¢è‰²å›¾åƒ
        test_img = Image.new('RGB', (256, 256), color=(255, 0, 0))  # çº¯çº¢è‰²
        processed = processor.preprocess(test_img, height=256, width=256)

        print(f"Test image (pure red) processed result:")
        print(f"  Shape: {processed.shape}")
        print(f"  Dtype: {processed.dtype}")
        print(f"  Range: [{processed.min():.6f}, {processed.max():.6f}]")
        print(f"  Mean per channel: {processed.mean(dim=[2,3])}")

        # å¦‚æœæ˜¯normalizeçš„è¯ï¼Œçº¢è‰²é€šé“åº”è¯¥æ˜¯(1-mean)/stdçš„å€¼

    def quick_fix_preprocess_subject_image(self, image: Image.Image, cond_size: int = 512) -> torch.Tensor:
        """
        å¿«é€Ÿä¿®å¤ç‰ˆæœ¬çš„é¢„å¤„ç†ï¼Œé¿å…ä½¿ç”¨pipelineçš„processor
        """
        # ç›´æ¥ä½¿ç”¨torchvisionçš„æ“ä½œï¼Œä¸ä¾èµ–pipeline processor
        from torchvision import transforms

        w, h = image.size
        scale = cond_size / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)

        # ä½¿ç”¨torchvisionçš„transforms
        transform = transforms.Compose([
            transforms.Resize((new_h, new_w)),
            transforms.ToTensor(),  # è‡ªåŠ¨å½’ä¸€åŒ–åˆ°[0,1]
        ])

        tensor = transform(image).unsqueeze(0)  # æ·»åŠ batchç»´åº¦

        # æ‰‹åŠ¨paddingåˆ°ç›®æ ‡å°ºå¯¸
        pad_h = cond_size - new_h
        pad_w = cond_size - new_w

        tensor = F.pad(tensor, 
                        (pad_w//2, pad_w-pad_w//2, pad_h//2, pad_h-pad_h//2), 
                        mode='constant', value=0)

        return tensor.to(device=self.device, dtype=torch.float32)

    def test_conversion_round_trip(self, original_image: Image.Image):
        """
        æµ‹è¯•è½¬æ¢çš„å¾€è¿”ä¸€è‡´æ€§
        """
        print("=" * 60)
        print("TESTING CONVERSION ROUND TRIP")
        print("=" * 60)

        # æµ‹è¯•1ï¼šåŸå§‹æ–¹æ³•
        print("Test 1: Original pipeline method")
        try:
            tensor1 = self.preprocess_subject_image(original_image)
            pil1 = self.tensor_to_pil(tensor1)
            tensor1_back = self.preprocess_subject_image(pil1)
            diff1 = torch.abs(tensor1 - tensor1_back).max()
            print(f"  Round trip difference: {diff1.item():.6f}")
        except Exception as e:
            print(f"  Error: {e}")
            diff1 = float('inf')

        # æµ‹è¯•2ï¼šå¿«é€Ÿä¿®å¤æ–¹æ³•
        print("Test 2: Quick fix method")
        try:
            tensor2 = self.quick_fix_preprocess_subject_image(original_image)
            pil2 = self.tensor_to_pil(tensor2)
            tensor2_back = self.quick_fix_preprocess_subject_image(pil2)
            diff2 = torch.abs(tensor2 - tensor2_back).max()
            print(f"  Round trip difference: {diff2.item():.6f}")
        except Exception as e:
            print(f"  Error: {e}")
            diff2 = float('inf')

        # æµ‹è¯•3ï¼šçº¯tensoræ–¹æ³•ï¼ˆæ— PILè½¬æ¢ï¼‰
        print("Test 3: Pure tensor method (no PIL conversion)")
        try:
            tensor3 = self.quick_fix_preprocess_subject_image(original_image)
            # æ·»åŠ å°æ‰°åŠ¨
            epsilon = 8/255
            delta = torch.randn_like(tensor3) * epsilon * 0.1
            adversarial_tensor = torch.clamp(tensor3 + delta, 0, 1)
            
            # ç›´æ¥è®¡ç®—å·®å¼‚ï¼Œä¸ç»è¿‡PIL
            diff3 = torch.abs(tensor3 - adversarial_tensor).max()
            expected_diff = torch.abs(delta).max()
            print(f"  Expected difference: {expected_diff.item():.6f}")
            print(f"  Actual difference: {diff3.item():.6f}")
            print(f"  Ratio: {(diff3/expected_diff).item():.3f}")
        except Exception as e:
            print(f"  Error: {e}")

        return diff1.item() if diff1 != float('inf') else None, \
                diff2.item() if diff2 != float('inf') else None

    def emergency_gradient_test(self, original_image: Image.Image):
        """
        ç´§æ€¥æ¢¯åº¦æµ‹è¯• - æœ€ç®€å•çš„ç‰ˆæœ¬
        """
        print("=" * 60)
        print("EMERGENCY GRADIENT TEST")
        print("=" * 60)

        # ä½¿ç”¨æœ€ç®€å•çš„tensoræ“ä½œ
        tensor = self.quick_fix_preprocess_subject_image(original_image)

        # åˆ›å»ºéœ€è¦æ¢¯åº¦çš„æ‰°åŠ¨
        delta = torch.zeros_like(tensor, requires_grad=True, device=self.device)

        print(f"Delta requires_grad: {delta.requires_grad}")

        # æœ€ç®€å•çš„æŸå¤±å‡½æ•°
        adversarial = tensor + delta
        simple_loss = adversarial.sum()  # æœ€ç®€å•çš„æŸå¤±

        print(f"Simple loss: {simple_loss.item():.6f}")
        print(f"Simple loss requires_grad: {simple_loss.requires_grad}")

        # åå‘ä¼ æ’­
        try:
            simple_loss.backward()
            if delta.grad is not None:
                print(f"âœ… Gradient computed! Norm: {delta.grad.norm().item():.6f}")
                return True
            else:
                print("âŒ Gradient is None!")
                return False
        except Exception as e:
            print(f"âŒ Backward failed: {e}")
            return False

        # åœ¨ä½ çš„ä¸»è¦æ”»å‡»æ–¹æ³•ä¹‹å‰ï¼Œå…ˆè¿è¡Œè¿™äº›è¯Šæ–­
    def run_emergency_diagnosis(self, original_image: Image.Image):
        """
        è¿è¡Œç´§æ€¥è¯Šæ–­
        """
        print("ğŸ” Running emergency diagnosis...")

        # 1. è°ƒæŸ¥processor
        self.investigate_pipeline_processor()

        # 2. æµ‹è¯•è½¬æ¢ä¸€è‡´æ€§
        diff1, diff2 = self.test_conversion_round_trip(original_image)

        # 3. æµ‹è¯•æ¢¯åº¦
        gradient_ok = self.emergency_gradient_test(original_image)

        # 4. ç»™å‡ºå»ºè®®
        print("\n" + "=" * 60)
        print("EMERGENCY DIAGNOSIS RESULTS")
        print("=" * 60)

        if diff1 is not None and diff1 > 0.01:
            print("âŒ Pipeline processor method has consistency issues")
            print("ğŸ’¡ Recommendation: Use quick_fix_preprocess_subject_image instead")

        if diff2 is not None and diff2 < 0.01:
            print("âœ… Quick fix method shows good consistency")

        if gradient_ok:
            print("âœ… Basic gradient flow is working")
        else:
            print("âŒ Gradient flow is broken")

        return {
            'pipeline_diff': diff1,
            'quickfix_diff': diff2,
            'gradient_ok': gradient_ok
        }
    
    def _init_pipeline(self, base_path: str, subject_lora_path: str):
        """åˆå§‹åŒ–EasyControl pipeline"""
        print("-" * 50)
        print(base_path)
        print("-" * 50)
        # åŠ è½½pipeline
        self.pipe = FluxPipeline.from_pretrained(
            base_path, 
            torch_dtype=torch.bfloat16, 
            device=self.device,
            local_files_only=True
        )
        
        # åŠ è½½transformer
        transformer = FluxTransformer2DModel.from_pretrained(
            base_path, 
            subfolder="transformer",
            torch_dtype=torch.bfloat16, 
            device=self.device,
            local_files_only=True
        )
        self.pipe.transformer = transformer
        self.pipe.to(self.device)
        
        # åŠ è½½subject control LoRA
        set_single_lora(self.pipe.transformer, subject_lora_path, lora_weights=[1], cond_size=512)
        
        # ç¡®ä¿æ¨¡å‹å‚æ•°éœ€è¦æ¢¯åº¦ï¼ˆç”¨äºå¯¹æŠ—æ”»å‡»ï¼‰
        self.pipe.transformer.requires_grad_(True)
        
        logger.info("EasyControl pipeline initialized successfully!")
    
    def clear_cache(self, transformer):
        for name, attn_processor in transformer.attn_processors.items():
            attn_processor.bank_kv.clear()    
    
    def preprocess_subject_image(self, image: Image.Image, cond_size: int = 512) -> torch.Tensor:
        """
        ä½¿ç”¨Pipelineçš„é¢„å¤„ç†é€»è¾‘å¤„ç†subjectå›¾ç‰‡
        å¤ç”¨Pipelineä¸­prepare_latentsçš„é¢„å¤„ç†éƒ¨åˆ†
        """
        w, h = image.size[:2]
        scale = cond_size / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)
        
        # ä½¿ç”¨pipelineè‡ªå¸¦çš„å›¾åƒå¤„ç†å™¨
        subject_image = self.pipe.image_processor.preprocess(image, height=new_h, width=new_w)
        subject_image = subject_image.to(dtype=torch.float32)
        
        # å¡«å……é€»è¾‘ - å¤ç”¨pipelineä¸­çš„padæ–¹æ³•
        pad_h = cond_size - subject_image.shape[-2]
        pad_w = cond_size - subject_image.shape[-1]
        subject_image = pad(
            subject_image,
            padding=(int(pad_w / 2), int(pad_h / 2), int(pad_w / 2), int(pad_h / 2)),
            fill=0
        )
        
        return subject_image.to(device=self.device)
    
    def tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """å°†tensorè½¬æ¢ä¸ºPILå›¾ç‰‡ - ä½¿ç”¨pipelineçš„åå¤„ç†é€»è¾‘"""
        if len(tensor.shape) == 4:
            tensor = tensor.squeeze(0)
        
        # ä½¿ç”¨pipelineçš„åå¤„ç†æ–¹æ³•
        tensor = tensor.cpu()
        tensor = torch.clamp(tensor, 0, 1)
        
        # [C, H, W] -> [H, W, C]
        if len(tensor.shape) == 3 and tensor.shape[0] == 3:
            tensor = tensor.permute(1, 2, 0)
        
        image_np = (tensor.detach().numpy() * 255).astype(np.uint8)
        return Image.fromarray(image_np)
    
    def generate_with_subject(self, prompt: str, subject_image: Image.Image, 
                            height: int = 1024, width: int = 1024, 
                            num_inference_steps: int = 20,
                            enable_grad: bool = True) -> Image.Image:
        """
        ä½¿ç”¨subject controlç”Ÿæˆå›¾ç‰‡
        """
        generation_func = self.pipe
        
        if enable_grad:
            # å¯ç”¨æ¢¯åº¦è®¡ç®—
            image = generation_func(
                prompt,
                height=height,
                width=width,
                guidance_scale=3.5,
                num_inference_steps=num_inference_steps,
                max_sequence_length=512,
                generator=torch.Generator("cpu").manual_seed(42),
                subject_images=[subject_image],
                cond_size=512,
            ).images[0]
        else:
            # ä¸éœ€è¦æ¢¯åº¦
            with torch.no_grad():
                image = generation_func(
                    prompt,
                    height=height,
                    width=width,
                    guidance_scale=3.5,
                    num_inference_steps=num_inference_steps,
                    max_sequence_length=512,
                    generator=torch.Generator("cpu").manual_seed(42),
                    subject_images=[subject_image],
                    cond_size=512,
                ).images[0]
        

        return image
    
    def compute_single_prompt_mse(self, original_img: Image.Image, 
                                 adversarial_img: Image.Image) -> torch.Tensor:
        """
        è®¡ç®—å•ä¸ªpromptä¸‹çš„MSEæŸå¤± - ä¼˜åŒ–ç‰ˆæœ¬
        """
        try:
            # ç”ŸæˆåŸå§‹å›¾ç‰‡ç»“æœ
            generated_original = self.generate_with_subject(
                self.attack_prompt, original_img, enable_grad=True
            )
            self.clear_cache(self.pipe.transformer)
            # ç”Ÿæˆå¯¹æŠ—å›¾ç‰‡ç»“æœ
            generated_adversarial = self.generate_with_subject(
                self.attack_prompt, adversarial_img, enable_grad=True
            )
            self.clear_cache(self.pipe.transformer)
            # ä½¿ç”¨pipelineçš„å›¾åƒå¤„ç†å™¨è¿›è¡Œé¢„å¤„ç†ä»¥ä¿æŒä¸€è‡´æ€§
            orig_tensor = self.pipe.image_processor.preprocess(generated_original)
            adv_tensor = self.pipe.image_processor.preprocess(generated_adversarial)
            
            # ç¡®ä¿tensoråœ¨åŒä¸€è®¾å¤‡ä¸Š
            orig_tensor = orig_tensor.to(self.device)
            adv_tensor = adv_tensor.to(self.device)
            
            # è®¡ç®—MSE
            mse = F.mse_loss(orig_tensor, adv_tensor)
            return mse
            
        except Exception as e:
            logger.warning(f"Failed to process prompt '{self.attack_prompt}': {e}")
            return torch.tensor(0.0, device=self.device)
    
    def pgd_attack_single_image(self, 
                               original_image: Image.Image,
                               epsilon: float = 8/255,
                               alpha: float = 2/255,
                               num_iterations: int = 50,
                               lambda_reg: float = 0.1) -> Tuple[torch.Tensor, Dict]:
        """
        å¯¹å•å¼ å›¾ç‰‡è¿›è¡ŒPGDæ”»å‡» - ä¼˜åŒ–ç‰ˆæœ¬
        """
        # ğŸ” é¦–å…ˆè¿è¡Œè¯Šæ–­
        print("ğŸ” Running emergency diagnosis...")
        diagnosis_results = self.run_emergency_diagnosis(original_image)
        
        # æ ¹æ®è¯Šæ–­ç»“æœé€‰æ‹©é¢„å¤„ç†æ–¹æ³•
        if diagnosis_results['pipeline_diff'] is None or diagnosis_results['pipeline_diff'] > 0.01:
            print("âš ï¸  Using quick fix preprocessing due to pipeline issues")
            preprocess_func = self.quick_fix_preprocess_subject_image
        else:
            print("âœ… Using original pipeline preprocessing")
            preprocess_func = self.preprocess_subject_image
            
        # ä½¿ç”¨é€‰å®šçš„é¢„å¤„ç†æ–¹æ³•
        original_tensor = preprocess_func(original_image, cond_size=512)
        original_tensor.requires_grad_(False)  # åŸå§‹å›¾ç‰‡ä¸éœ€è¦æ¢¯åº¦
        
        # åˆå§‹åŒ–éšæœºå™ªå£°
        delta = torch.zeros_like(original_tensor, requires_grad=True)
        delta.data = (torch.rand_like(original_tensor) - 0.5) * 2 * epsilon
        
        attack_info = {
            'loss_history': [],
            'mse_history': [],
            'epsilon': epsilon,
            'alpha': alpha,
            'num_iterations': num_iterations,
            'lambda_reg': lambda_reg,
            'attack_prompt': self.attack_prompt,
            'used_quick_fix': diagnosis_results['pipeline_diff'] is None or diagnosis_results['pipeline_diff'] > 0.01
        }
        
        logger.info(f"Using attack prompt: '{self.attack_prompt}'")
        
        for i in range(num_iterations):
            delta.requires_grad_(True)
            
            # ç”Ÿæˆå¯¹æŠ—å›¾ç‰‡
            adversarial_tensor = torch.clamp(original_tensor + delta, 0, 1)
            adversarial_image = self.tensor_to_pil(adversarial_tensor)
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é€‰å®šçš„é¢„å¤„ç†æ–¹æ³•è¿›è¡Œæµ‹è¯•ï¼Œè€Œä¸æ˜¯å›ºå®šä½¿ç”¨åŸå§‹æ–¹æ³•
            reconstructed_tensor = preprocess_func(adversarial_image)
            actual_diff = torch.abs(original_tensor - reconstructed_tensor).max()
            
            print(f"Iter {i+1}: Expected diff={torch.abs(delta).max().item():.6f}, "
                f"Actual diff={actual_diff.item():.6f}")
            
            if actual_diff.item() < 1e-6:
                print("âš ï¸  WARNING: æ‰°åŠ¨åœ¨è½¬æ¢è¿‡ç¨‹ä¸­ä¸¢å¤±äº†ï¼")

            # return mseæŸå¤±
            mse_loss = self.compute_single_prompt_mse(original_image, adversarial_image)
            
            # è®¡ç®—æ­£åˆ™åŒ–é¡¹ (LâˆèŒƒæ•°)
            reg_loss = torch.max(torch.abs(delta))
            
            # æ€»æŸå¤±ï¼šæœ€å¤§åŒ–MSEï¼Œæœ€å°åŒ–å™ªå£°
            total_loss = -mse_loss + lambda_reg * reg_loss
            
            # è®°å½•å†å²
            attack_info['loss_history'].append(total_loss.item())
            attack_info['mse_history'].append(mse_loss.item())
            
            logger.info(f"Iter {i+1}/{num_iterations}: MSE={mse_loss.item():.6f}, "
                       f"Reg={reg_loss.item():.6f}, Total={total_loss.item():.6f}")
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            
            # PGDæ›´æ–°
            with torch.no_grad():
                delta.data = delta.data + alpha * delta.grad.sign()
                
                # æŠ•å½±åˆ°epsilonçº¦æŸèŒƒå›´
                delta.data = torch.clamp(delta.data, -epsilon, epsilon)
                
                # ç¡®ä¿å¯¹æŠ—å›¾ç‰‡åœ¨[0,1]èŒƒå›´å†…
                delta.data = torch.clamp(original_tensor + delta.data, 0, 1) - original_tensor
            
            # æ¸…é›¶æ¢¯åº¦
            delta.grad = None
            
        return delta.detach(), attack_info
    
    def process_dataset(self, 
                       dataset: LAIONFaceDataset,
                       batch_size: int = 1,
                       epsilon: float = 8/255,
                       alpha: float = 2/255,
                       num_iterations: int = 50,
                       lambda_reg: float = 0.1,
                       save_frequency: int = 100,
                       resume_from: Optional[int] = None) -> None:
        """
        å¤„ç†æ•´ä¸ªæ•°æ®é›†
        """
        def custom_collate_fn(batch):
            return batch 
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=custom_collate_fn)
        
        # åˆ›å»ºè¿›åº¦æ¡
        total_samples = len(dataset)
        start_idx = resume_from or 0
        
        # ç”¨äºç»Ÿè®¡
        success_count = 0
        total_mse_improvement = 0.0
        
        # ç»“æœæ—¥å¿—
        results_log = []
        
        logger.info(f"Starting adversarial generation for {total_samples} images")
        logger.info(f"Parameters: epsilon={epsilon}, alpha={alpha}, iterations={num_iterations}")
        logger.info(f"Attack prompt: '{self.attack_prompt}'")
        
        with tqdm(dataloader, desc="Processing images") as pbar:
            for batch_idx, batch in enumerate(pbar):
                # å¦‚æœéœ€è¦æ¢å¤ï¼Œè·³è¿‡å·²å¤„ç†çš„
                if batch_idx < start_idx:
                    continue
                
                try:
                    # è·å–å›¾ç‰‡ï¼ˆå½“å‰batch_size=1ï¼‰
                    original_image = batch[0]['image']
                    image_path = batch[0]['image_path']
                    image_idx = batch[0]['index']
                    
                    # æ£€æŸ¥å›¾ç‰‡è´¨é‡
                    if original_image.size[0] < 256 or original_image.size[1] < 256:
                        logger.warning(f"Skipping small image {image_path}")
                        continue
                    
                    # æ‰§è¡ŒPGDæ”»å‡»
                    adversarial_noise, attack_info = self.pgd_attack_single_image(
                        original_image=original_image,
                        epsilon=epsilon,
                        alpha=alpha,
                        num_iterations=num_iterations,
                        lambda_reg=lambda_reg
                    )
                    
                    # ç”Ÿæˆå¯¹æŠ—å›¾ç‰‡
                    original_tensor = self.preprocess_subject_image(original_image, cond_size=512)
                    adversarial_tensor = torch.clamp(original_tensor + adversarial_noise, 0, 1)
                    adversarial_image = self.tensor_to_pil(adversarial_tensor)
                    
                    # è®¡ç®—æœ€ç»ˆçš„MSEæå‡
                    final_mse = attack_info['mse_history'][-1] if attack_info['mse_history'] else 0
                    
                    # ä¿å­˜ç»“æœ
                    clean_path = self.clean_dir / f"{image_idx:06d}_clean.png"
                    adversarial_path = self.adversarial_dir / f"{image_idx:06d}_adversarial.png"
                    
                    original_image.save(clean_path)
                    adversarial_image.save(adversarial_path)
                    
                    # è®°å½•ç»“æœ
                    result_entry = {
                        'image_idx': image_idx,
                        'original_path': str(image_path),
                        'clean_path': str(clean_path),
                        'adversarial_path': str(adversarial_path),
                        'final_mse': final_mse,
                        'attack_info': attack_info,
                        'timestamp': datetime.now().isoformat()
                    }
                    results_log.append(result_entry)
                    
                    # ç»Ÿè®¡
                    if final_mse > 0.01:  # è®¤ä¸ºæˆåŠŸçš„é˜ˆå€¼
                        success_count += 1
                    total_mse_improvement += final_mse
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.set_postfix({
                        'Success': f"{success_count}/{batch_idx+1}",
                        'Avg_MSE': f"{total_mse_improvement/(batch_idx+1):.4f}",
                        'Current_MSE': f"{final_mse:.4f}"
                    })
                    
                    # å®šæœŸä¿å­˜æ—¥å¿—
                    if (batch_idx + 1) % save_frequency == 0:
                        self._save_progress_log(results_log, batch_idx + 1)
                        logger.info(f"Saved progress at sample {batch_idx + 1}")
                    
                except Exception as e:
                    logger.error(f"Failed to process image {batch_idx}: {e}")
                    continue
                
                # å†…å­˜æ¸…ç†
                if batch_idx % 10 == 0:
                    torch.cuda.empty_cache()
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_final_results(results_log, success_count, total_samples)
        logger.info(f"Completed! Success rate: {success_count}/{total_samples} ({100*success_count/total_samples:.1f}%)")
    
    def _save_progress_log(self, results_log: List[Dict], current_idx: int):
        """ä¿å­˜è¿›åº¦æ—¥å¿—"""
        log_path = self.logs_dir / f"progress_{current_idx:06d}.json"
        with open(log_path, 'w') as f:
            json.dump(results_log, f, indent=2)
    
    def _save_final_results(self, results_log: List[Dict], success_count: int, total_samples: int):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        
        # ä¿å­˜è¯¦ç»†æ—¥å¿—
        final_log_path = self.logs_dir / "final_results.json"
        with open(final_log_path, 'w') as f:
            json.dump(results_log, f, indent=2)
        
        # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
        summary = {
            'total_samples': total_samples,
            'successful_attacks': success_count,
            'success_rate': success_count / total_samples if total_samples > 0 else 0,
            'average_mse': sum(r['final_mse'] for r in results_log) / len(results_log) if results_log else 0,
            'completion_time': datetime.now().isoformat()
        }
        
        summary_path = self.logs_dir / "summary.json"
        with open(summary_path, 'w') as f:
            json.dump(summary, f, indent=2)
        
        logger.info(f"Results saved to {self.output_dir}")

def main():
    parser = argparse.ArgumentParser(description="Optimized large-scale adversarial sample generation for EasyControl")
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument("--data_root", type=str, required=True,
                       help="Root directory of LAIONFace dataset")
    parser.add_argument("--subset_size", type=int, default=None,
                       help="Use only a subset of the dataset")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--base_model", type=str, default="/openbayes/input/input0",
                       help="Base FLUX model path")
    parser.add_argument("--subject_lora", type=str, default="/openbayes/input/input0/subject.safetensors",
                       help="Subject LoRA model path")
    
    # æ”»å‡»å‚æ•°
    parser.add_argument("--epsilon", type=float, default=8/255,
                       help="Maximum perturbation magnitude")
    parser.add_argument("--alpha", type=float, default=2/255,
                       help="PGD step size")
    parser.add_argument("--num_iterations", type=int, default=50,
                       help="Number of PGD iterations")
    parser.add_argument("--lambda_reg", type=float, default=0.1,
                       help="Regularization coefficient")
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument("--output_dir", type=str, default="./adversarial_results",
                       help="Output directory")
    parser.add_argument("--device", type=str, default="cuda",
                       help="Computing device")
    parser.add_argument("--batch_size", type=int, default=1,
                       help="Batch size (only 1 supported currently)")
    parser.add_argument("--save_frequency", type=int, default=100,
                       help="Save progress every N samples")
    parser.add_argument("--resume_from", type=int, default=None,
                       help="Resume from specific sample index")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ•°æ®é›†
    logger.info(f"Loading dataset from {args.data_root}")
    dataset = LAIONFaceDataset(args.data_root, args.subset_size)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    logger.info("Initializing optimized adversarial generator")
    generator = OptimizedAdversarialGenerator(
        base_path=args.base_model,
        subject_lora_path=args.subject_lora,
        device=args.device,
        output_dir=args.output_dir
    )
    
    # å¼€å§‹å¤„ç†
    logger.info("Starting optimized large-scale adversarial generation")
    generator.process_dataset(
        dataset=dataset,
        batch_size=args.batch_size,
        epsilon=args.epsilon,
        alpha=args.alpha,
        num_iterations=args.num_iterations,
        lambda_reg=args.lambda_reg,
        save_frequency=args.save_frequency,
        resume_from=args.resume_from
    )
    
    logger.info("Generation completed!")

if __name__ == "__main__":
    main()

# ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
"""
# åŸºæœ¬ä½¿ç”¨
python adversarial_generator.py \
    --data_root /openbayes/input/input0/sample_faces \
    --output_dir ./results \
    --epsilon 0.03137 \
    --num_iterations 50

# é«˜è´¨é‡æ”»å‡»ï¼ˆæ›´å¤šè¿­ä»£ï¼‰
python optimized_adversarial_generator.py \
    --data_root /path/to/laionface \
    --epsilon 0.03137 \
    --alpha 0.00784 \
    --num_iterations 30 \
    --output_dir ./high_quality_results

# ä»ä¸­æ–­å¤„æ¢å¤
python optimized_adversarial_generator.py \
    --data_root /path/to/laionface \
    --resume_from 500 \
    --output_dir ./results
"""